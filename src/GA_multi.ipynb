{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from geneticalgorithm2 import geneticalgorithm2 as ga \n",
    "from scipy.spatial.distance import cdist\n",
    "import pandas as pd\n",
    "import math\n",
    "import heapq\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shores = np.loadtxt(\"shore.csv\", dtype='float', delimiter=',')\n",
    "elevations = np.loadtxt(\"elevation.csv\", dtype='float', delimiter=',')\n",
    "\n",
    "# shores = shores - np.amin(shores)\n",
    "elevations = np.abs(elevations)\n",
    "# elevations = elevations - np.amin(elevations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_crowds(pop: np.ndarray):\n",
    "\n",
    "    #Create ranks based on domination\n",
    "    #   Iterate through the population and get candidates such that tehre are no other candidates with better objective values for BOTH functions (can exist 1)\n",
    "    #   These candidates are given smallest current rank and removed from population to repeat and rank all others\n",
    "    popN = pop.shape[0]\n",
    "\n",
    "\n",
    "    #Dictionary of all candidates \"dominated\" by given index candidate\n",
    "    dominated_sets = {}\n",
    "    #Dictionary of all candidates in rank order\n",
    "    rank_sets = {key: [] for key in range(1,popN+1,1)}\n",
    "\n",
    "    ranks = [popN]*popN\n",
    "    crowdings = [0]*popN\n",
    "    F = []\n",
    "\n",
    "    #Go through population for each candidate and check whether there exists candidates that (1) it dominates or (2) is dominated by\n",
    "    for p in range(popN):\n",
    "        sp = []\n",
    "        dnp = 0\n",
    "        for q in range(popN):\n",
    "            if pop[p,1] < pop[q,1] and pop[p,2] < pop[q,2]: #p dominates q\n",
    "                sp.append(q)\n",
    "            elif pop[q,1] < pop[p,1] and pop[q,2] < pop[p,2]: #q dominates p\n",
    "                dnp = dnp + 1\n",
    "\n",
    "        #There are no candidate taht dominate given candidate, it is given rank 1\n",
    "        if dnp == 0:\n",
    "            ranks[p] = 1 \n",
    "            rank_sets[1] = rank_sets[1] + [p]\n",
    "            F.append(p)\n",
    "        dominated_sets[p] = [sp,dnp] \n",
    "\n",
    "\n",
    "    i = 1\n",
    "    #Iterate through all top rank candidate and find next candidates FROM their lists of dominations (now these are next highest rank candidates)\n",
    "    while (len(F) != 0):\n",
    "        Q = []\n",
    "        for p in F:\n",
    "\n",
    "            for q in dominated_sets[p][0]:\n",
    "                dominated_sets[q][1] = dominated_sets[q][1] - 1\n",
    "                #Removed all current rank candidates from given candidate's dominated by list, since it is 0 it is among best next rank\n",
    "                if dominated_sets[q][1] == 0:\n",
    "                    ranks[q] = i + 1\n",
    "                    rank_sets[i + 1] = rank_sets[i + 1] + [q]\n",
    "                    Q.append(q)\n",
    "        i = i + 1\n",
    "        F = Q\n",
    "\n",
    "    #objs = [\"fitness_func\",\"cable_total\"]\n",
    "\n",
    "    #Get crowding distance by getting distance to neighbors of given candidate (distances are proportional to min/max of given objective)\n",
    "    for r in range(1,i,1):\n",
    "        l = len(rank_sets[r])\n",
    "        arr = np.array(rank_sets[r])        \n",
    "        for o in range(2):            \n",
    "            #sort by obj            \n",
    "            sort_arr = arr[np.argsort(pop[:,o+1][arr])]\n",
    "\n",
    "            #set crowd for 1 and final to 10000 (these are expected to contain more information and will be chosen if required)\n",
    "            crowdings[sort_arr[0]] = -1000000\n",
    "            crowdings[sort_arr[l-1]] = -1000000\n",
    "\n",
    "            #Get min/max and get distance prortion to their difference\n",
    "            o_min = np.copy(pop[sort_arr[0],o+1])\n",
    "            o_max = np.copy(pop[sort_arr[l-1],o+1])            \n",
    "            for n in range(1,l-1):\n",
    "                if o_min == o_max:\n",
    "                    crowdings[sort_arr[n]] = crowdings[sort_arr[n]] + 0\n",
    "                elif crowdings[sort_arr[n]] != -1000000:\n",
    "                    #subtract since we are later sorting ascending \n",
    "                    crowdings[sort_arr[n]] = crowdings[sort_arr[n]]  -  ((pop[sort_arr[n-1],o+1] + pop[sort_arr[n+1],o+1]) / (o_max - o_min) )\n",
    "    #use the ranks to get crowding distnaces\n",
    "    return [ranks,crowdings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_func(pop):\n",
    "    popN = pop.shape[0]\n",
    "    ranks = [popN]*popN\n",
    "    #Crowding not necessary, returned for consistency\n",
    "    crowdings = [0]*popN\n",
    "\n",
    "    #rank based on both wake(turbine costs) and cable length\n",
    "    #Get the min,max for both objectives and rank based on the standing of given candidate in the population\n",
    "    min_wake = np.min(pop[:,1])\n",
    "    max_wake = np.max(pop[:,1])\n",
    "\n",
    "    min_cable = np.min(pop[:,2])\n",
    "    max_cable = np.max(pop[:,2])\n",
    "\n",
    "    costs = [0] * popN\n",
    "    for p in range(popN):\n",
    "        #arbitrary weights 75% and 25% respectively\n",
    "        costs[p] = (0.75*( ( pop[p,1] - min_wake ) / (max_wake-min_wake))) + (0.25*( (pop[p,2] - min_cable )/(max_cable-min_cable)))\n",
    "\n",
    "    #Ranks are sort order for new combination values\n",
    "    ranks = np.argsort(costs)\n",
    "    return [ranks,crowdings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Prim_mst(nodes,edges,center):\n",
    "    #Implemented based on CodeSavant's implementation for my context\n",
    "    nodes_mst = set()\n",
    "\n",
    "    mst_costs = 0\n",
    "    nodesN = len(nodes)\n",
    "\n",
    "    #Edges stored ad dict\n",
    "    edges_all = { tuple(key): [] for key in nodes}\n",
    "    \n",
    "    #add all nodes to heap\n",
    "    for [s,e,c] in edges:\n",
    "        heapq.heappush(edges_all[tuple(s)],(c,tuple(e)))\n",
    "        heapq.heappush(edges_all[tuple(e)],(c,tuple(s)))\n",
    "\n",
    "    cost, dest = 0,1\n",
    "    while len(nodes_mst) < nodesN:\n",
    "        nodes_smallest = tuple(center)\n",
    "\n",
    "        #Go through nodes to get the node that is connected with the next edge\n",
    "        for n in nodes_mst:\n",
    "            while len(edges_all[n]) > 0 and edges_all[n][0][dest] in nodes_mst:\n",
    "                heapq.heappop(edges_all[n])\n",
    "            \n",
    "            #no end nodes from given node are outside of MST\n",
    "            if len(edges_all[n]) == 0:\n",
    "                continue\n",
    "            \n",
    "            #nodes found\n",
    "            if len(edges_all[nodes_smallest]) == 0 or edges_all[n][0][cost] < edges_all[nodes_smallest][0][cost]:\n",
    "                nodes_smallest = n\n",
    "\n",
    "        #Pop from heap (lowest one present at top) to get the correct edge with smallest weight\n",
    "        to_add = heapq.heappop(edges_all[nodes_smallest])\n",
    "\n",
    "        #add cost to MST total (distance + elevation values of each turbine - connection from bottom of sea to turbine)\n",
    "        mst_costs += to_add[cost]\n",
    "        mst_costs += elevations[to_add[dest][0],to_add[dest][1]]\n",
    "        mst_costs += elevations[nodes_smallest[0],nodes_smallest[1]]\n",
    "\n",
    "        #add the nodes to the MST (handles duplicates)\n",
    "        nodes_mst.add(nodes_smallest)\n",
    "        nodes_mst.add(to_add[dest])\n",
    "    return mst_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offshore_dist(center):\n",
    "    #return distance to shore in m\n",
    "    return shores[center[0],center[1]]\n",
    "\n",
    "\n",
    "\n",
    "def get_array_dist(xes,yes,center):\n",
    "    #Uses MST to give array cable length\n",
    "\n",
    "    #Create arrray of nodes\n",
    "    nodes = [[x,y] for x,y in zip(xes,yes)]\n",
    "    if center not in nodes:\n",
    "        nodes.append(center)\n",
    "\n",
    "    #creates edges (the graph will start out as complete) [start,end,length] \n",
    "    pairs = [(a, b) for idx, a in enumerate(nodes) for b in nodes[idx + 1:]]\n",
    "    edges = []\n",
    "    for (s,e) in pairs:\n",
    "        edges.append([s,e, 140*math.dist([s[0], s[1]], [e[0], e[1]]) ])\n",
    "    \n",
    "\n",
    "    dist = Prim_mst(nodes,edges,center)\n",
    "    return dist\n",
    "\n",
    "def cable_total(ones):\n",
    "    xes = [i%50 for i in ones]\n",
    "    yes = [int(i/50) for i in ones]\n",
    "\n",
    "    #calculate the centerpoint and corresponding distance to shore\n",
    "    center = [ int(np.mean(xes)), int(np.mean(yes)) ]\n",
    "    export = get_offshore_dist(center)\n",
    "\n",
    "    #calculate interconnection of the turbines\n",
    "    array = get_array_dist(xes,yes,center)\n",
    "\n",
    "    #return the total distance values\n",
    "    return export + array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = []\n",
    "#import all the interaction matricies created beforehand and add to array (flattened versions of the matrices)\n",
    "for i in range(50):\n",
    "    for j in range(50):\n",
    "        mat = np.loadtxt(open(\"interactionMats/\"+str(i)+\"_\"+str(j)+\".csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "        arr = np.array(mat).flatten()\n",
    "\n",
    "        interactions.append(arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fitness_func(ones):\n",
    "    #add all the interaction values\n",
    "    wake = 0\n",
    "    if len(ones) > 50:\n",
    "        return 1000000\n",
    "\n",
    "    for i in ones:\n",
    "        tot = 0\n",
    "        for j in ones:\n",
    "            tot += interactions[i][j]\n",
    "        wake += tot\n",
    "    return wake\n",
    "def make_arr(ones: np.ndarray):\n",
    "    arr = [0] * 2500\n",
    "    for i in ones:\n",
    "        arr[i] = 1\n",
    "    return np.array(arr)\n",
    "def make_random(number, turbine,fitnessT):\n",
    "    pop = []\n",
    "    for i in range(number):\n",
    "        turbines = np.random.choice(np.arange(0, 2500), turbine, replace = False)\n",
    "        binary =  make_arr(turbines)\n",
    "\n",
    "        wake = fitness_func(turbines)\n",
    "        cable = cable_total(turbines)\n",
    "        pop.append([binary,wake,cable,0,0])\n",
    "    \n",
    "    #pareto ranks\n",
    "    pop = np.array(pop)\n",
    "    paretos = globals()[fitnessT](pop)\n",
    "    #crowding distances\n",
    "    new_pop = np.c_[pop[:,0],pop[:,1],pop[:,2],paretos[0],paretos[1]]\n",
    "    return new_pop\n",
    "def sort_tot(pop):\n",
    "    #sort by the parent then order by wake values\n",
    "    return pop[np.lexsort((pop[:,4],pop[:,3]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_mutation(bitstring, prob):\n",
    "   \n",
    "    if np.random.rand() < prob:\n",
    "        lens = len(bitstring)\n",
    "        i = int(np.random.rand() * lens)\n",
    "\n",
    "        # flip the bit and one with opposite value (to keep same number of turbines)\n",
    "        prev = np.copy(bitstring[i])\n",
    "        opp = np.where(bitstring == (1-prev))[0]\n",
    "        bitstring[i] = 1 - np.copy(prev)\n",
    "\n",
    "        bitstring[  opp[int(np.random.rand()*len(opp))]  ] = np.copy(prev)\n",
    "    return bitstring\n",
    "\n",
    "def uniform_crossover(x: np.ndarray, y: np.ndarray):\n",
    "    #randomly selects 1's from either sides\n",
    "    x1 = np.where(x == 1)[0]\n",
    "    y1 = np.where(y == 1)[0]\n",
    "\n",
    "    ofs1 = []\n",
    "    ofs2 = []\n",
    "    \n",
    "    all = list(set(x1) | set(y1))\n",
    "\n",
    "    ofs1 = random.sample(all,50)\n",
    "    ofs2 = random.sample(all,50)\n",
    "\n",
    "\n",
    "    ofs1 = make_arr(ofs1)\n",
    "    ofs2 = make_arr(ofs2)    \n",
    "    return [ofs1, ofs2]\n",
    "\n",
    "\n",
    "def tournament_selection(pop):\n",
    "    #ramdomly select 4 parents and pick 2 in each block according to thier fitness\n",
    "    pairs = [] #indexes of parents \n",
    "    scores = pop[:,1]\n",
    "\n",
    "    #get random selections (size of population\n",
    "    parents = np.random.choice(a=np.arange(0,scores.size),size=2*scores.size,replace=True)\n",
    "\n",
    "        \n",
    "    for i in range(int(parents.size/4)):\n",
    "        #pick parent 1 based on pareto (or if same using crowding dist)\n",
    "        par1 = 0\n",
    "        if pop[parents[(i*4)],3] == pop[parents[(i*4)+1],3]:\n",
    "            #same pareto rank\n",
    "            par1 = np.argsort(pop[parents[i*4:(i*4)+2],4])[0]\n",
    "        else:\n",
    "            par1 = np.argsort(pop[parents[i*4:(i*4)+2],3])[0]\n",
    "        \n",
    "        #pick parent 2 based on pareto (or if same using crowding dist)\n",
    "        par2 = 2\n",
    "        if pop[parents[(i*4)+2],3] == pop[parents[(i*4)+3],3]:\n",
    "            #same pareto rank\n",
    "            par2 = 2+ np.argsort(pop[parents[(i*4)+2:(i*4)+4],4])[0]\n",
    "        else:\n",
    "            par2 = 2+ np.argsort(pop[parents[(i*4)+2:(i*4)+4],3])[0]\n",
    "        \n",
    "        pairs.append([pop[parents[(i*4)+par1]][0],pop[parents[(i*4)+par2]][0]])\n",
    "\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_ga(popN,fitnessT,iter):\n",
    "    #We create same number of children as parents for NSGA2\n",
    "    pop =  make_random(popN,50,fitnessT)\n",
    "    pop = sort_tot(pop)\n",
    "\n",
    "    prob_mutation = 0.1 #probability of a child going through mutation\n",
    "    for it in range(iter):\n",
    "        #We default to tournament selection since NSGA2 calls for it\n",
    "        parent_pairs = tournament_selection(pop)\n",
    "        children = []\n",
    "        for [a,b] in parent_pairs:\n",
    "\n",
    "            #Create children using uniform crossover and rand mutation\n",
    "            child_pair = uniform_crossover(a,b)\n",
    "            c1_bin = rand_mutation(child_pair[0],prob_mutation)\n",
    "            c2_bin = rand_mutation(child_pair[1],prob_mutation)\n",
    "            \n",
    "            #Get the turbine positions to calcualte objective values\n",
    "            ones_c1 = []\n",
    "            ones_c2 = []\n",
    "            for i in range(2500):\n",
    "                if c1_bin[i] == 1:\n",
    "                    ones_c1.append(i)\n",
    "                if c2_bin[i] == 1:\n",
    "                    ones_c2.append(i)\n",
    "\n",
    "            #add childred to population\n",
    "            children.append([c1_bin,fitness_func(ones_c1),cable_total(ones_c1),0,0])\n",
    "            children.append([c2_bin,fitness_func(ones_c2),cable_total(ones_c2),0,0])\n",
    "\n",
    "        children = np.array(children)\n",
    "        total_pop = np.concatenate((children, pop))\n",
    "        \n",
    "        #get pareto ranks and crowding distances for next pop \n",
    "        paretos = globals()[fitnessT](total_pop)\n",
    "        next_pop = np.c_[total_pop[:,0],total_pop[:,1],total_pop[:,2],paretos[0],paretos[1]]\n",
    "        \n",
    "        #remake population with 50/50 split old and new - elitist \n",
    "        pop = sort_tot(next_pop)\n",
    "        pop = pop[:popN,]\n",
    "\n",
    "    #Best candidate is in rank 1\n",
    "    rank1s = [p for p in pop if p[3]==1]\n",
    "    #I decided to go with best wake performing candidate as best candidate\n",
    "    rank1s = sorted(rank1s, key=lambda x: x[1])\n",
    "    return rank1s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final = multi_ga(1000,1000)\n",
    "\n",
    "#best = multi_ga(100,\"pareto_crowds\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ones = []\n",
    "# for i in range(2500):\n",
    "#     if my_data2[i] == 1:\n",
    "#         ones.append(i)\n",
    "\n",
    "# xes = [i%50 for i in ones]\n",
    "# yes = [int(i/50) for i in ones]\n",
    "\n",
    "#calculate the centerpoint and corresponding distance to shore\n",
    "# center = [ int(np.mean(xes)), int(np.mean(yes)) ]\n",
    "# nodes = [[x,y] for x,y in zip(xes,yes)]\n",
    "# if center not in nodes:\n",
    "#     nodes.append(center)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
